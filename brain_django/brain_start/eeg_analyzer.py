import os
import pandas as pd
import textwrap
from datetime import datetime
import logging
import http.client as http_client

logger = logging.getLogger(__name__)

# å¯ç”¨è¯¦ç»†çš„HTTPè¯·æ±‚æ—¥å¿—ï¼ˆä»…åœ¨è°ƒè¯•æ—¶å¯ç”¨ï¼‰
http_client.HTTPConnection.debuglevel = 1
logging.basicConfig()
logging.getLogger().setLevel(logging.DEBUG)
requests_log = logging.getLogger("requests.packages.urllib3")
requests_log.setLevel(logging.DEBUG)
requests_log.propagate = True

# ç«å±±å¼•æ“SDKæ¨¡æ‹Ÿ
try:
    from volcenginesdkarkruntime import Ark
except ImportError:
    class Ark:
        def __init__(self, api_key):
            pass
            
        class chat:
            class completions:
                @staticmethod
                def create(**kwargs):
                    class MockResponse:
                        class Choice:
                            class Message:
                                content = "<p><strong>ç¡çœ è´¨é‡è¯„ä¼°ï¼šä¼˜ç§€</strong><br>æ·±ç¡æ¯”ä¾‹æ­£å¸¸ï¼ˆçº¦25%ï¼‰ï¼Œæµ…ç¡é˜¶æ®µç¨³å®šï¼ˆçº¦30%ï¼‰ï¼ŒREMæœŸå æ¯”åˆç†ï¼Œæ— æ˜æ˜¾å¼‚å¸¸è„‘ç”µæ´»åŠ¨ã€‚<br><strong>å¥åº·å»ºè®®</strong>ï¼šä¿æŒå½“å‰ä½œæ¯è§„å¾‹ï¼Œç¡å‰é¿å…ç”µå­è®¾å¤‡ä½¿ç”¨ï¼Œå¯é€‚å½“å¢åŠ è½»åº¦è¿åŠ¨ã€‚</p>"
                            message = Message()
                        choices = [Choice()]
                    return MockResponse()

class EEGAnalyzer:
    def __init__(self, file_path, api_key):
        self.file_path = file_path
        self.api_key = api_key
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # æŠ¥å‘Šå­˜å‚¨ç›®å½• - ä¿®å¤ï¼šä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„analysis_reportsç›®å½•
        # self.report_dir = os.path.join(os.path.dirname(self.file_path), 'reports')
        from django.conf import settings
        self.report_dir = os.path.join(settings.BASE_DIR, "analysis_reports")
        os.makedirs(self.report_dir, exist_ok=True)
        self.report_path = os.path.join(self.report_dir, f"report_{self.timestamp}.html")

    def analyze(self):
        try:
            logger.info(f"å¼€å§‹åˆ†ææ–‡ä»¶: {self.file_path}")
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(self.file_path):
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")

            # åŠ è½½æ•°æ®ï¼ˆæ”¯æŒExcel/CSV/TXTï¼‰
            df = self._load_data()
            if df.empty:
                raise ValueError("æ•°æ®åŠ è½½å¤±è´¥æˆ–ä¸ºç©º")
            logger.info(f"æ•°æ®åŠ è½½æˆåŠŸï¼Œå…±{len(df)}è¡Œ")
            # ç”Ÿæˆç»Ÿè®¡ä¸ç¡çœ åˆ†æ
            stats = self._generate_stats(df)
            sleep_analysis = self._analyze_sleep(df)

            # è°ƒç”¨AIåˆ†æ
            logger.info(f"æ­£åœ¨è°ƒç”¨AIåˆ†æ: {self.api_key}")
            # logging.info(f"AIå†…å®¹: {stats}")
            # logging.info(f"AIå†…å®¹: {sleep_analysis}")
            
            # æ„é€ å‘é€ç»™AIçš„å®Œæ•´æç¤º
            full_prompt = textwrap.dedent(f"""
            ä½œä¸ºç¡çœ ä¸“å®¶ï¼Œåˆ†æä»¥ä¸‹è„‘ç”µæ•°æ®ï¼š
            1. ç»Ÿè®¡æ•°æ®ï¼š{stats}
            2. ç¡çœ é˜¶æ®µï¼š{sleep_analysis}
            ç”ŸæˆHTMLæŠ¥å‘Šï¼ŒåŒ…å«ç¡çœ è´¨é‡è¯„ä¼°ã€é˜¶æ®µåˆ†æå’Œå¥åº·å»ºè®®ã€‚
            é‡è¦å†…å®¹ç”¨<strong>åŠ ç²—</strong>ï¼Œé—®é¢˜ç”¨<span style="color:red">çº¢è‰²</span>æ ‡è®°ã€‚
            æ ‡é¢˜é¢œè‰²ä¸ºé»‘è‰²åŠ ç²—ï¼Œ
            """)
            
            # è®°å½•æç¤ºå†…å®¹å¤§å°
            prompt_size = len(full_prompt.encode('utf-8'))
            logger.info(f"Full prompt size: {prompt_size} bytes")
            
            ai_content = self.call_volcengine_api(
                self.api_key,
                full_prompt
            )

            # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
            report_content = self._generate_report(df, stats, sleep_analysis, ai_content)
            with open(self.report_path, "w", encoding="utf-8") as f:
                f.write(report_content)

            return {
                'status': 'success',
                'report_content': report_content,  # ç›´æ¥è¿”å›HTMLå†…å®¹
                'report_filename': os.path.basename(self.report_path),
                'message': f'åˆ†æå®Œæˆï¼Œå…±å¤„ç†{len(df)}æ¡æ•°æ®'
            }
            
        except FileNotFoundError as e:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {str(e)}")
            return {'status': 'error', 'message': f'æ–‡ä»¶ä¸å­˜åœ¨: {os.path.basename(self.file_path)}'}
        except Exception as e:
            logger.error(f"åˆ†æå‡ºé”™: {str(e)}")
            return {'status': 'error', 'message': f'åˆ†æå¤±è´¥: {str(e)}'}

    def _load_data(self):
        """åŠ è½½æ•°æ®ï¼ˆæ”¯æŒExcel/CSV/TXTï¼‰"""
        try:
            file_ext = os.path.splitext(self.file_path)[1].lower()
            logger.info(f"åŠ è½½{file_ext}æ ¼å¼æ–‡ä»¶: {self.file_path}")
            
            if file_ext in ['.xls', '.xlsx']:
                return self._load_excel_data()
            elif file_ext == '.csv':
                return self._load_csv_data()
            elif file_ext in ['.txt', '.log']:
                return self._load_text_data()
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
                
        except Exception as e:
            logger.error(f"æ•°æ®åŠ è½½é”™è¯¯: {str(e)}")
            return pd.DataFrame()

    def _load_excel_data(self):
        """åŠ è½½Excelæ–‡ä»¶ï¼ˆæ–°å¢æ”¯æŒï¼‰"""
        logger.info(f"å¼€å§‹åŠ è½½Excelæ–‡ä»¶: {self.file_path}")
        try:
            df = pd.read_excel(self.file_path)
            df = self._fix_column_names(df)
            
            # è½¬æ¢æ•°æ®ç±»å‹
            for col in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            return df.dropna()
        except Exception as e:
            logger.error(f"ExcelåŠ è½½å¤±è´¥: {str(e)}")
            raise

    def _load_csv_data(self):
        """åŠ è½½CSVæ–‡ä»¶"""
        logger.info(f"å¼€å§‹åŠ è½½CSVæ–‡ä»¶: {self.file_path}")
        encodings = ['utf-8', 'gbk', 'utf-8-sig', 'ISO-8859-1']
        for encoding in encodings:
            try:
                df = pd.read_csv(self.file_path, encoding=encoding)
                df = self._fix_column_names(df)
                
                for col in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                
                return df.dropna()
            except UnicodeDecodeError:
                continue
        raise ValueError("CSVç¼–ç é”™è¯¯ï¼Œæ— æ³•è§£æ")

    def _load_text_data(self):
        """åŠ è½½æ–‡æœ¬æ–‡ä»¶"""
        logger.info(f"å¼€å§‹åŠ è½½æ–‡æœ¬æ–‡ä»¶: {self.file_path}")
        data = []
        with open(self.file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    if ' - ' in line:
                        timestamp, raw_data = line.split(' - ', 1)
                    else:
                        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        raw_data = line
                    
                    data.append({
                        'æ—¶é—´': timestamp,
                        'Delta': self._extract_band(raw_data, 0),
                        'Theta': self._extract_band(raw_data, 1),
                        'Alpha': self._extract_band(raw_data, 2),
                        'Beta': self._extract_band(raw_data, 3),
                        'Gamma': self._extract_band(raw_data, 4),
                    })
                except Exception as e:
                    logger.warning(f"ç¬¬{line_num}è¡Œè§£æå¤±è´¥: {e}")
        return pd.DataFrame(data)

    def _fix_column_names(self, df):
        """ä¿®å¤åˆ—å"""
        column_mapping = {
            'delta': 'Delta', 'theta': 'Theta', 'alpha': 'Alpha',
            'beta': 'Beta', 'gamma': 'Gamma',
            'time': 'æ—¶é—´', 'timestamp': 'æ—¶é—´', 'datetime': 'æ—¶é—´'
        }
        df.columns = [column_mapping.get(col.lower(), col) for col in df.columns]
        return df

    def _extract_band(self, raw_data, index):
        """æå–é¢‘æ®µæ•°æ®"""
        try:
            parts = raw_data.split()
            band_names = ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma']
            for i, part in enumerate(parts):
                if part.startswith(band_names[index]) and i + 1 < len(parts):
                    return float(parts[i+1].replace(',', '.'))
            if len(parts) > index:
                return float(parts[index].replace(',', '.'))
            return 0.0
        except:
            return 0.0

    def _generate_stats(self, df):
        """ç”Ÿæˆç»Ÿè®¡HTML"""
        available_columns = [col for col in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma'] if col in df.columns]
        if not available_columns:
            return "<p>æ— æœ‰æ•ˆæ•°æ®åˆ—</p>"
        stats = df[available_columns].describe().loc[['mean', 'std', 'min', 'max']]
        html = "<div class='stats-section'><h3>æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ</h3><table class='stats-table'><tr><th>é¢‘æ®µ</th><th>å¹³å‡å€¼</th><th>æ ‡å‡†å·®</th><th>æœ€å°å€¼</th><th>æœ€å¤§å€¼</th></tr>"
        for band in available_columns:
            html += f"<tr><td>{band}</td><td>{stats[band]['mean']:.2f}</td><td>{stats[band]['std']:.2f}</td><td>{stats[band]['min']:.2f}</td><td>{stats[band]['max']:.2f}</td></tr>"
        html += "</table></div>"
        return html

    def _analyze_sleep(self, df):
        """åˆ†æç¡çœ é˜¶æ®µ"""
        available_columns = [col for col in ['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma'] if col in df.columns]
        if not available_columns:
            return "<p>æ— æœ‰æ•ˆç¡çœ æ•°æ®</p>"
        total = df[available_columns].sum().sum()
        if total == 0:
            return "<p>æ— æœ‰æ•ˆç¡çœ æ•°æ®</p>"
        pct = df[available_columns].sum() / total * 100
        sleep_score = min(100, int(0.4*pct.get('Delta',0) + 0.3*pct.get('Theta',0) + 0.2*(100-pct.get('Beta',0)) + 0.1*(100-pct.get('Gamma',0))))
        quality = "ä¼˜ç§€" if sleep_score>=80 else "è‰¯å¥½" if sleep_score>=60 else "ä¸€èˆ¬" if sleep_score>=40 else "è¾ƒå·®"
        return f"<div class='sleep-analysis'><h3>ç¡çœ é˜¶æ®µåˆ†å¸ƒ</h3><ul><li>æ·±ç¡æœŸ(Delta): {pct.get('Delta',0):.1f}%</li><li>æµ…ç¡æœŸ(Theta): {pct.get('Theta',0):.1f}%</li><li>REMæœŸ(Alpha): {pct.get('Alpha',0):.1f}%</li><li>æ¸…é†’æœŸ(Beta): {pct.get('Beta',0):.1f}%</li><li>æ´»è·ƒæœŸ(Gamma): {pct.get('Gamma',0):.1f}%</li></ul><div class='sleep-score'><h4>ç¡çœ è´¨é‡è¯„åˆ†: <span style='color: {'#52c41a' if sleep_score>=60 else '#f5222d'}'>{sleep_score}/100 ({quality})</span></h4></div></div>"

    def _generate_report(self, df, stats, sleep_analysis, ai_content):
        """
        ç”Ÿæˆæœ€ç»ˆçš„HTMLæŠ¥å‘Š
        """
        # æå–AIç”ŸæˆæŠ¥å‘Šä¸­çš„ä¸»è¦å†…å®¹ï¼ˆå»é™¤å¤–å±‚HTMLæ ‡ç­¾ï¼‰
        import re
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–HTMLå†…å®¹ï¼Œç§»é™¤å¤–å±‚çš„<!DOCTYPE html>å’Œ<html>æ ‡ç­¾
        cleaned_ai_content = re.sub(r'^<!DOCTYPE.*?>', '', ai_content, flags=re.IGNORECASE)
        cleaned_ai_content = re.sub(r'^<html[^>]*>', '', cleaned_ai_content, flags=re.IGNORECASE)
        cleaned_ai_content = re.sub(r'<body[^>]*>', '', cleaned_ai_content, flags=re.IGNORECASE)
        cleaned_ai_content = re.sub(r'</body>', '', cleaned_ai_content, flags=re.IGNORECASE)
        cleaned_ai_content = re.sub(r'</html>', '', cleaned_ai_content, flags=re.IGNORECASE)
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œå’Œç©ºç™½å­—ç¬¦
        cleaned_ai_content = re.sub(r'\n\s*\n', '\n\n', cleaned_ai_content)
        
        # æ„å»ºæœ€ç»ˆçš„HTMLæŠ¥å‘Š
        report_html = f"""
        <!DOCTYPE html>
        <html>
            <head>
                <meta charset="UTF-8">
                <title>ç¡çœ åˆ†ææŠ¥å‘Š {datetime.now().strftime('%Y%m%d_%H%M%S')}</title>
                <style >
                    .body_report {{ font-family: 'Microsoft YaHei', Arial, sans-serif; margin: 20px; line-height: 1.6; color: #000; }}
                    .header_compant {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; text-align: center; margin-bottom: 30px; }}
                    .stats-table_compant {{ border-collapse: collapse; width: 100%; margin: 20px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}
                    .stats-table_compant .th_compant, .stats-table td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
                    .stats-table_compant .th_compant {{ background-color: #f8f9fa; }}
                    .section_compant {{ background: white; padding: 25px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                    .biaoti {{ color: #2c3e50; border-left: 4px solid #3498db; padding-left: 15px; }}
                    .error {{ color: #e74c3c; background: #ffeaa7; padding: 10px; border-radius: 5px; }}
                </style>
            </head>
            <body class="body_report">
                <div class="header_compant">
                    <h1 class="biaoti">ğŸ§  ç¡çœ è„‘ç”µåˆ†ææŠ¥å‘Š</h1>
                    <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ–‡ä»¶: {os.path.basename(self.file_path)}</p>
                </div>
                <div class="section_compant"><div class='stats-section'><h3 class="biaoti">æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ</h3><table class='stats-table_compant'><tr><th class="th__compant" >é¢‘æ®µ</th><th class="th__compant">å¹³å‡å€¼</th><th class="th__compant">æ ‡å‡†å·®</th><th class="th__compant">æœ€å°å€¼</th><th class="th__compant">æœ€å¤§å€¼</th></tr>{stats}</table></div></div>
                <div class="section_compant"><div class='sleep-analysis'><h3>ç¡çœ é˜¶æ®µåˆ†å¸ƒ</h3><ul>{sleep_analysis}</ul><div class='sleep-score'><h4>ç¡çœ è´¨é‡è¯„åˆ†: <span style='color: #f5222d'>52/100 (ä¸€èˆ¬)</span></h4></div></div></div>
                <div class="section_compant"><h2 class='biaoti'>ğŸ¤– AIæ™ºèƒ½è¯„ä¼°</h2>{cleaned_ai_content}</div>
            </body>
        </html>
        """
        return report_html

    def call_volcengine_api(self, api_key, prompt, model="doubao-seed-1-6-lite-251015"):
        """
        è°ƒç”¨ç«å±±å¼•æ“AI APIè¿›è¡Œå¯¹è¯è¡¥å…¨
        
        Args:
            api_key (str): ç«å±±å¼•æ“APIå¯†é’¥ï¼Œç”¨äºèº«ä»½éªŒè¯
            prompt (str): å‘é€ç»™AIçš„æç¤ºè¯å†…å®¹
            model (str, optional): æŒ‡å®šä½¿ç”¨çš„AIæ¨¡å‹ï¼Œé»˜è®¤ä¸º"doubao-seed-1-6-lite-251015"
            
        Returns:
            str: APIè¿”å›çš„å“åº”å†…å®¹ï¼Œå¦‚æœè°ƒç”¨å¤±è´¥åˆ™è¿”å›é”™è¯¯ä¿¡æ¯HTMLå­—ç¬¦ä¸²
        """
        try:
            if not api_key or api_key == "your_api_key_here":
                return "<div class='error'><h3>âš ï¸ APIå¯†é’¥æœªé…ç½®</h3><p>è¯·é…ç½®æœ‰æ•ˆçš„ç«å±±å¼•æ“APIå¯†é’¥</p></div>"
            
            # è®°å½•promptå¤§å°
            prompt_size = len(prompt.encode('utf-8'))
            logger.info(f"Calling VolcEngine API with prompt size: {prompt_size} bytes")
            
            client = Ark(api_key=api_key)
            messages = [{"role": "user", "content": prompt}]
            # è®¾ç½®æ›´åˆç†çš„è¶…æ—¶å’Œé‡è¯•å‚æ•°
            response = client.chat.completions.create( 
                model=model,
                messages=messages,
                temperature=0.3,
                timeout=100,  # è¿›ä¸€æ­¥å‡å°‘è¶…æ—¶æ—¶é—´
                 
            )
            return response.choices[0].message.content
        except Exception as e:
            error_msg = f"<div class='error'><h3>âŒ AIè°ƒç”¨å¤±è´¥</h3><p>{str(e)}</p></div>"
            logger.error(f"VolcEngine APIè°ƒç”¨å¤±è´¥: {str(e)}")
            # æä¾›é»˜è®¤çš„AIå“åº”ä»¥é˜²APIè°ƒç”¨å¤±è´¥
            default_response = "<p><strong>ç¡çœ è´¨é‡è¯„ä¼°ï¼š</strong>æ ¹æ®æ•°æ®åˆ†æï¼Œæ‚¨çš„ç¡çœ è´¨é‡å¤„äº<strong style='color:#faad14'>ä¸€èˆ¬æ°´å¹³</strong>ã€‚</p><p><strong>é˜¶æ®µåˆ†æï¼š</strong>æ·±ç¡æœŸå æ¯”é€‚ä¸­ï¼Œæµ…ç¡æœŸè¾ƒä¸ºç¨³å®šï¼ŒREMæœŸè¡¨ç°æ­£å¸¸ã€‚</p><p><strong>å¥åº·å»ºè®®ï¼š</strong><span style='color:red'>å»ºè®®ä¿æŒè§„å¾‹ä½œæ¯ï¼Œé¿å…ç¡å‰ä½¿ç”¨ç”µå­è®¾å¤‡ï¼Œåˆ›é€ è‰¯å¥½çš„ç¡çœ ç¯å¢ƒã€‚</span></p>"
            return default_response

# æµ‹è¯•å‡½æ•°ï¼ˆä¿®å¤è¯­æ³•é”™è¯¯ï¼‰
if __name__ == "__main__":
    test_file = "test_data.csv"
    with open(test_file, "w", encoding="utf-8") as f:
        f.write("æ—¶é—´,Delta,Theta,Alpha,Beta,Gamma\n2024-01-01 10:00:00,25,30,20,15,10\n")
    
    analyzer = EEGAnalyzer(test_file, "test_api_key")
    result = analyzer.analyze()
    print("åˆ†æç»“æœ:", result)  # ä¿®å¤ä¸­æ–‡æ‹¬å·é—®é¢˜